{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n",
    "\n",
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.0\n",
      "You have 1 GPUs\n",
      "The selected GPU is GPU 0\n",
      "- Name: NVIDIA GeForce RTX 3080 Ti\n",
      "- All properties: _CudaDeviceProperties(name='NVIDIA GeForce RTX 3080 Ti', major=8, minor=6, total_memory=12287MB, multi_processor_count=80)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print('PyTorch version:', torch.__version__)\n",
    "if torch.cuda.is_available():\n",
    "  print(\"You have %d GPUs\" % torch.cuda.device_count())\n",
    "  gpu_id = torch.cuda.current_device()\n",
    "  print(\"The selected GPU is GPU\", gpu_id)\n",
    "  print(\"- Name:\", torch.cuda.get_device_name(gpu_id))\n",
    "  print(\"- All properties:\",torch.cuda.get_device_properties(gpu_id))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>TicketClass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SiblingsSpouses</th>\n",
       "      <th>ParentChildren</th>\n",
       "      <th>TicketNumber</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.00</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.00</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  TicketClass  \\\n",
       "886          887         0            2   \n",
       "887          888         1            1   \n",
       "888          889         0            3   \n",
       "889          890         1            1   \n",
       "890          891         0            3   \n",
       "\n",
       "                                         Name     Sex   Age  SiblingsSpouses  \\\n",
       "886                     Montvila, Rev. Juozas    male  27.0                0   \n",
       "887              Graham, Miss. Margaret Edith  female  19.0                0   \n",
       "888  Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN                1   \n",
       "889                     Behr, Mr. Karl Howell    male  26.0                0   \n",
       "890                       Dooley, Mr. Patrick    male  32.0                0   \n",
       "\n",
       "     ParentChildren TicketNumber   Fare Cabin Embarked  \n",
       "886               0       211536  13.00   NaN        S  \n",
       "887               0       112053  30.00   B42        S  \n",
       "888               2   W./C. 6607  23.45   NaN        S  \n",
       "889               0       111369  30.00  C148        C  \n",
       "890               0       370376   7.75   NaN        Q  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['PassengerId','Survived','TicketClass','Name','Sex','Age','SiblingsSpouses','ParentChildren','TicketNumber','Fare','Cabin','Embarked']\n",
    "raw_data_train = pd.read_csv('train.csv', header=0, names=column_names, delimiter=\",\", skipinitialspace=True) #header=0 + names allows to override headers\n",
    "\n",
    "column_names = ['PassengerId','TicketClass','Name','Sex','Age','SiblingsSpouses','ParentChildren','TicketNumber','Fare','Cabin','Embarked']\n",
    "raw_data_test = pd.read_csv('train.csv', header=0, names=column_names, delimiter=\",\", skipinitialspace=True) #header=0 + names allows to override headers\n",
    "\n",
    "raw_data_train.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll analyze the data in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId        0.000000\n",
       "Survived           0.000000\n",
       "TicketClass        0.000000\n",
       "Name               0.000000\n",
       "Sex                0.000000\n",
       "Age                0.198653\n",
       "SiblingsSpouses    0.000000\n",
       "ParentChildren     0.000000\n",
       "TicketNumber       0.000000\n",
       "Fare               0.000000\n",
       "Cabin              0.771044\n",
       "Embarked           0.002245\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_train.isna().sum()/len(raw_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TicketClass</th>\n",
       "      <td>891.0</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>714.0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>0.42</td>\n",
       "      <td>20.1250</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>80.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SiblingsSpouses</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ParentChildren</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>891.0</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.9104</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>31.0</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count       mean        std   min      25%      50%   75%  \\\n",
       "TicketClass      891.0   2.308642   0.836071  1.00   2.0000   3.0000   3.0   \n",
       "Age              714.0  29.699118  14.526497  0.42  20.1250  28.0000  38.0   \n",
       "SiblingsSpouses  891.0   0.523008   1.102743  0.00   0.0000   0.0000   1.0   \n",
       "ParentChildren   891.0   0.381594   0.806057  0.00   0.0000   0.0000   0.0   \n",
       "Fare             891.0  32.204208  49.693429  0.00   7.9104  14.4542  31.0   \n",
       "\n",
       "                      max  \n",
       "TicketClass        3.0000  \n",
       "Age               80.0000  \n",
       "SiblingsSpouses    8.0000  \n",
       "ParentChildren     6.0000  \n",
       "Fare             512.3292  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats = raw_data_train.describe()\n",
    "train_stats.pop(\"Survived\") # the column we want to predict its values\n",
    "train_stats.pop(\"PassengerId\")\n",
    "train_stats = train_stats.transpose()\n",
    "train_stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After inspecting the dataset, the following considerations can be made:\n",
    "- PassengerId and TicketNumer are apparently useless features for the task so we'll drop them\n",
    "- The cabin attribute is unknown for 77% of the samples, so we'll drop the feature\n",
    "- We'll drop the two samples without embarkment informations\n",
    "- Even if for almost 20% of the dataset the age is unknown, it is probably an important feature, so we'll drop the samples without age info for semplicity\n",
    "- We must use One-Hot Encoding for the categorical features 'TicketClass', 'Sex' and 'Embarked'\n",
    "- We can extract useful information about the social status of the person from the Name attribute\n",
    "- Numeric features must be normalized\n",
    "\n",
    "We define a function to preprocess raw data. It will be used to preprocess both the training set and later the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_raw_data(raw_data: pd.DataFrame):\n",
    "  data = raw_data.copy()\n",
    "  #Drop unnecessary features\n",
    "  data = data.drop(['PassengerId','TicketNumber','Cabin'],axis=1)\n",
    "  #Drop samples without age or without embarkment info\n",
    "  data = data.dropna()\n",
    "  #One-Hot encode categorical features\n",
    "  sex = data.pop('Sex')\n",
    "  data['Male'] = (sex == 'male') * 1.0\n",
    "  data['Female'] = (sex == 'female') * 1.0\n",
    "  tClass = data.pop('TicketClass')\n",
    "  data['UpperClass'] = (tClass == 1) * 1.0\n",
    "  data['MiddleClass'] = (tClass == 2) * 1.0\n",
    "  data['LowerClass'] = (tClass == 3) * 1.0\n",
    "  embarked = data.pop('Embarked')\n",
    "  data['CherbourgPort'] = (embarked == 'C') * 1.0\n",
    "  data['QueenstownPort'] = (embarked == 'Q') * 1.0\n",
    "  data['SouthamptonPort'] = (embarked == 'S') * 1.0\n",
    "  #Extract the title from the name\n",
    "  titles = data.pop('Name').str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "  data['Mr'] = (titles == 'Mr') * 1.0\n",
    "  data['Miss/Mrs/Ms/Lady'] = ((titles == 'Miss') | (titles == 'Mrs') | (titles == 'Ms') | (titles == 'Lady') | (titles == 'Mme') | (titles == 'Mlle')) * 1.0\n",
    "  data['Master'] = (titles == 'Master') * 1.0\n",
    "  data['Rev/Dr/Major/Col/Contess/Capt/Sir/Don/Jonkheer'] = ((titles == 'Rev') | (titles == 'Dr') | (titles == 'Major') | (titles == 'Col') | (titles == 'the Countess') | (titles == 'Capt') | (titles == 'Sir') | (titles == 'Don') | (titles == 'Jonkheer') ) * 1.0\n",
    "  return data\n",
    "\n",
    "def normalize_data(raw_data: pd.DataFrame, stats: pd.DataFrame):\n",
    "  data = raw_data\n",
    "  #Data normalization based only on the statistics\n",
    "  for col in ['Age', 'SiblingsSpouses', 'ParentChildren', 'Fare']:\n",
    "    data[col] = (data[col] - stats['mean'][col]) / stats['std'][col]\n",
    "  return data\n",
    "\n",
    "def preprocess_train_val(raw_train_df: pd.DataFrame, raw_val_df: pd.DataFrame):\n",
    "  # Preprocess data\n",
    "  train_df = preprocess_raw_data(raw_train_df)\n",
    "  val_df = preprocess_raw_data(raw_val_df)\n",
    "\n",
    "  # Extract statistics for data normalization only from the training set\n",
    "  train_stats = train_df.describe()\n",
    "  train_stats = train_stats.transpose()\n",
    "\n",
    "  train_df = normalize_data(train_df, train_stats)\n",
    "  val_df = normalize_data(val_df, train_stats)\n",
    "  return (train_df,val_df)\n",
    "\n",
    "# train_stats = raw_data_train.describe()\n",
    "# train_stats.pop(\"Survived\") # the column we want to predict its values\n",
    "# train_stats.pop(\"PassengerId\")\n",
    "# train_stats = train_stats.transpose()\n",
    "# train_data = preprocess_raw_data(raw_data_train,train_stats)\n",
    "# train_data.tail()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and validation extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = raw_data_train.copy()\n",
    "train_data = dataset.sample(frac=0.8, random_state=0)\n",
    "val_data = dataset.drop(train_data.index)\n",
    "\n",
    "(train_data, val_data) = preprocess_train_val(train_data, val_data)\n",
    "train_labels = train_data.pop(\"Survived\")\n",
    "val_labels = val_data.pop(\"Survived\")\n",
    "# train_data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "def df2tensor(df):\n",
    "    return torch.from_numpy(df.values).float().cuda()\n",
    "train_dataset = TensorDataset(df2tensor(train_data), df2tensor(train_labels))\n",
    "val_dataset = TensorDataset(df2tensor(val_data), df2tensor(val_labels))\n",
    "\n",
    "num_train_samples, num_features = train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, input_size=num_features, hidden_size=[64, 64], output_size=1):\n",
    "        # init function executed once when the nn is instantiated\n",
    "        super().__init__() # execute the nn.Module init function\n",
    "\n",
    "        # layers with trainable parameters\n",
    "        all_size = [input_size, ] + hidden_size + [output_size, ] # [num_features, 64, 64, 1]\n",
    "        linears = []\n",
    "        for in_size, out_size in zip(all_size[:-1], all_size[1:]):\n",
    "            linears.append(nn.Linear(in_size, out_size)) # fully-connected layer\n",
    "        self.linears = nn.ModuleList(linears)\n",
    "\n",
    "        # layers without trainable parameters\n",
    "        self.sigmoid = nn.Sigmoid()                      # sigmoid activation layer\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        # forward function executed when an input is passed to the nn\n",
    "        for i, l in enumerate(self.linears):\n",
    "            x = l(x)                     # apply the i-th fully-connected layer\n",
    "            if i < len(self.linears) - 1:\n",
    "                x = self.sigmoid(x)   # apply the sigmoid activation layer, but for the output\n",
    "            else: #Output layer\n",
    "                x = self.softmax(x)\n",
    "        return x.squeeze()               # model output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayerPerceptron(\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=16, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      "  (softmax): Softmax(dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def one_epoch(model, lossFunction, optimizer, train_loader, val_loader, writer, epoch_num):\n",
    "  i_start = epoch_num * len(train_loader)\n",
    "  for i, (X, y) in enumerate(train_loader):\n",
    "    X = X.cuda()\n",
    "    y = y.cuda()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    o = model(X)\n",
    "    l = lossFunction(o, y)\n",
    "\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    mae = (o.detach() - y.detach()).abs().mean()\n",
    "\n",
    "    # print(\"- batch loss and accuracy : {:.7f}\\t{:.4f}\".format(l.detach().item(), acc))\n",
    "    writer.add_scalar('train/loss', l.detach().item(), i_start+i)\n",
    "    writer.add_scalar('train/mae', mae, i_start+i)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    err = []\n",
    "    for X, y in val_loader:\n",
    "      X = X.cuda()\n",
    "      y = y.cuda()\n",
    "\n",
    "      err.append(y - model(X))\n",
    "\n",
    "    err = torch.concatenate(err)\n",
    "    val_loss = (err**2).mean().item()\n",
    "    val_mae = err.abs().mean().item()\n",
    "\n",
    "    # print(\"Validation loss and accuracy : {:.7f}\\t{:.4f}\".format(val_loss, val_accuracy))\n",
    "    writer.add_scalar('val/loss', val_loss, i_start+i)\n",
    "    writer.add_scalar('val/mae', val_mae, i_start+i)\n",
    "  return val_loss, val_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tensorboard import notebook\n",
    "\n",
    "def start_tensorboard(log_dir):\n",
    "  writer = SummaryWriter(os.path.join(\"runs\", log_dir))\n",
    "\n",
    "  # run tensorboard in background\n",
    "  ! killall tensorboard\n",
    "  %load_ext tensorboard\n",
    "  %tensorboard --logdir ./runs\n",
    "\n",
    "  notebook.list() # View open TensorBoard instances\n",
    "\n",
    "  return writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "batch_size = 512\n",
    "lr = .01\n",
    "momentum = .9\n",
    "lambda_reg = 0\n",
    "\n",
    "epochs = 200\n",
    "early_stopping_patience = 40\n",
    "\n",
    "# dataloader, network, optimizer for each fold\n",
    "train_loader = DataLoader(train_dataset, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False)\n",
    "\n",
    "model = MultiLayerPerceptron().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(),\n",
    "                            lr=lr,\n",
    "                            weight_decay=lambda_reg,\n",
    "                            momentum=momentum)\n",
    "\n",
    "# early stopping and best model saving\n",
    "early_stopping_counter = early_stopping_patience\n",
    "min_val_loss = 1e10\n",
    "\n",
    "experiment_name = 'test'\n",
    "writer = start_tensorboard(experiment_name)\n",
    "\n",
    "val_losses = torch.zeros(epochs, 1)\n",
    "val_accuracies = torch.zeros(epochs, 1)\n",
    "\n",
    "for e in range(epochs):\n",
    "    print(\"FOLD {} - EPOCH {}\".format(0, e))\n",
    "    val_loss, val_accuracy = one_epoch(model, lossFunction, optimizer, train_loader, val_loader, writer, e)\n",
    "\n",
    "    # store the validation metrics\n",
    "    val_losses[e] = val_loss\n",
    "    val_accuracies[e] = val_accuracy\n",
    "    torch.save(val_losses, os.path.join(experiment_name,'val_losses.pth'))\n",
    "    torch.save(val_accuracies, os.path.join(experiment_name,'val_accuracies.pth'))\n",
    "\n",
    "    # save the best model and check the early stopping criteria\n",
    "    if val_loss < min_val_loss: # save the best model\n",
    "        min_val_loss = val_loss\n",
    "        early_stopping_counter = early_stopping_patience # reset early stopping counter\n",
    "        torch.save(model.state_dict(), os.path.join(experiment_name,'fold_{}_best_model.pth'.format(0)))\n",
    "        print(\"- saved best model\")\n",
    "\n",
    "    if e>0: # early stopping counter update\n",
    "        if val_losses[e, 0] > val_losses[e-1, 0]:\n",
    "            early_stopping_counter -= 1 # update early stopping counter\n",
    "        else:\n",
    "            early_stopping_counter = early_stopping_patience # reset early stopping counter\n",
    "    if early_stopping_counter == 0: # early stopping\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
